{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNCCVfjTesLn2Dbii24PJsY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PozzOver13/learning/blob/main/programming/20250211_cookiecutter_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cookiecutter Data Science"
      ],
      "metadata": {
        "id": "EpkDHJLJ4fwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "- https://cookiecutter-data-science.drivendata.org/#\n",
        "- https://drivendata.co/blog/ccds-v2\n",
        "- https://www.youtube.com/watch?v=dxUMBVTvbWw&t=53s"
      ],
      "metadata": {
        "id": "GzMXfRUR7Hsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Cookiecutter 4 Data Science?\n",
        "\n",
        "    a logical, reasonably standardized but flexible project structure for data science\n",
        "\n",
        "La libreria **Cookiecutter Data Science** è un template progettato per strutturare in modo ordinato e riproducibile i progetti di data science. È basato su **Cookiecutter**, uno strumento Python per generare progetti da modelli predefiniti.\n",
        "\n",
        "### 🚀 **Caratteristiche principali**:\n",
        "- **Struttura chiara e modulare**: Organizza il codice, i dati e la documentazione in cartelle specifiche.\n",
        "- **Facile riproducibilità**: Favorisce l'uso di ambienti virtuali e versionamento del codice.\n",
        "- **Separazione tra dati grezzi e trasformati**: Minimizza il rischio di sovrascrittura accidentale dei dati originali.\n",
        "- **Pipeline standardizzata**: Promuove l'uso di script modulari e notebook Jupyter per l'analisi e il modello.\n",
        "\n",
        "### 📂 **Struttura tipica del progetto**\n",
        "Quando si usa il template, viene creata una struttura simile a questa:\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "├── LICENSE            <- Open-source license if one is chosen\n",
        "├── Makefile           <- Makefile with convenience commands like `make data` or `make train`\n",
        "├── README.md          <- The top-level README for developers using this project.\n",
        "├── data\n",
        "│   ├── external       <- Data from third party sources.\n",
        "│   ├── interim        <- Intermediate data that has been transformed.\n",
        "│   ├── processed      <- The final, canonical data sets for modeling.\n",
        "│   └── raw            <- The original, immutable data dump.\n",
        "│\n",
        "├── docs               <- A default mkdocs project; see www.mkdocs.org for details\n",
        "│\n",
        "├── models             <- Trained and serialized models, model predictions, or model summaries\n",
        "│\n",
        "├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),\n",
        "│                         the creator's initials, and a short `-` delimited description, e.g.\n",
        "│                         `1.0-jqp-initial-data-exploration`.\n",
        "│\n",
        "├── pyproject.toml     <- Project configuration file with package metadata for\n",
        "│                         {{ cookiecutter.module_name }} and configuration for tools like black\n",
        "│\n",
        "├── references         <- Data dictionaries, manuals, and all other explanatory materials.\n",
        "│\n",
        "├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.\n",
        "│   └── figures        <- Generated graphics and figures to be used in reporting\n",
        "│\n",
        "├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.\n",
        "│                         generated with `pip freeze > requirements.txt`\n",
        "│\n",
        "├── setup.cfg          <- Configuration file for flake8\n",
        "│\n",
        "└── {{ cookiecutter.module_name }}   <- Source code for use in this project.\n",
        "    │\n",
        "    ├── __init__.py             <- Makes {{ cookiecutter.module_name }} a Python module\n",
        "    │\n",
        "    ├── config.py               <- Store useful variables and configuration\n",
        "    │\n",
        "    ├── dataset.py              <- Scripts to download or generate data\n",
        "    │\n",
        "    ├── features.py             <- Code to create features for modeling\n",
        "    │\n",
        "    ├── modeling                \n",
        "    │   ├── __init__.py\n",
        "    │   ├── predict.py          <- Code to run model inference with trained models          \n",
        "    │   └── train.py            <- Code to train models\n",
        "    │\n",
        "    └── plots.py                <- Code to create visualizations   \n",
        "```\n",
        "\n",
        "\n",
        "### 🔧 **Installazione e utilizzo**\n",
        "1. **Installazione di Cookiecutter**:\n",
        "E' preferibile usare pipx install che installa il pacchetto in un ambiente virtuale isolato e lo rende disponibile a livello globale (quindi non nell'environment attivo).\n",
        "\n",
        "   ```bash\n",
        "   pipx install cookiecutter\n",
        "   ```\n",
        "2. **Creazione di un nuovo progetto con il template**:\n",
        "   ```bash\n",
        "   cookiecutter https://github.com/drivendata/cookiecutter-data-science\n",
        "   ```\n",
        "3. **Seguire le istruzioni interattive** per personalizzare il progetto.\n",
        "\n",
        "### 🎯 **Vantaggi**\n",
        "✔️ Migliora la collaborazione e la manutenibilità  \n",
        "✔️ Evita il disordine nei file del progetto  \n",
        "✔️ Favorisce buone pratiche ingegneristiche  \n",
        "✔️ Semplifica l'integrazione in pipeline di produzione  \n",
        "\n",
        "Ti interessa un approfondimento su qualche aspetto, ad esempio su come adattarlo ai tuoi progetti in PySpark o SageMaker? 😊"
      ],
      "metadata": {
        "id": "vswdfDK35LIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What's new in V2?\n",
        "\n",
        "Ci sono diverse novità entusiasmanti in **CCDS V2**. Queste includono:  \n",
        "\n",
        "- **Un nuovo entrypoint CLI, `ccds`**. Controllare il punto di accesso a riga di comando ci dà maggiore controllo sul processo di Cookiecutter, abilitando molte delle funzionalità descritte di seguito.  \n",
        "\n",
        "- **Maggiore flessibilità**: molte richieste di funzionalità riguardavano la possibilità di scegliere strumenti diversi rispetto ai valori predefiniti della V1 per svolgere un determinato compito. Man mano che gli strumenti evolvono e vengono adottati più ampiamente, vogliamo rendere più semplice per gli utenti utilizzare le migliori opzioni nel proprio template di progetto.  \n",
        "\n",
        "- **Documentazione migliorata** con più esempi, spiegazioni più chiare sulle scelte e sugli strumenti, e un aspetto più moderno. Trova la versione più recente su [cookiecutter-data-science.drivendata.org](https://cookiecutter-data-science.drivendata.org/) (la vecchia documentazione verrà presto reindirizzata qui).  \n",
        "\n",
        "- **Test per CCDS**: la V1 non includeva test. Ora eseguiamo test su diversi sistemi operativi per verificare effettivamente tutti i passaggi di Cookiecutter. Questo processo ha portato alla scoperta di errori nascosti nei vari OS, ma ora possiamo apportare modifiche future con maggiore sicurezza.  \n",
        "\n",
        "- **Una visione per l'estendibilità**: maggiore automazione, più contributi dalla community, più possibilità di personalizzazione e una collaborazione più efficace.  \n",
        "\n",
        "Abbiamo accennato al fatto che il template segue una filosofia simile a Unix: concatenare i migliori strumenti per ogni attività invece di cercare di essere una soluzione unica e monolitica. Vedremo nel dettaglio ogni attività per cui **CCDS V2** fornisce strumenti e analizzeremo come funzionano."
      ],
      "metadata": {
        "id": "0acLpx5s7W7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why\n",
        "\n",
        "**Other people will thank you**\n",
        "\n",
        "**You will thank you**\n",
        "\n",
        "**Nothing here is binding**\n",
        "\n",
        "> \"Consistency within a project is more important. Consistency within one module or function is the most important. ... However, know when to be inconsistent -- sometimes style guide recommendations just aren't applicable. When in doubt, use your best judgment. Look at other examples and decide what looks best. And don't hesitate to ask!\"  PEP 8\n",
        "\n"
      ],
      "metadata": {
        "id": "o4resYIi82Vw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opinions\n",
        "\n",
        "**Data analysis is a directed acyclic graph**\n",
        "\n",
        "**Raw data is immutable**\n",
        "\n",
        "**Data should (mostly) not be kept in source control**\n",
        "\n",
        "**Tools for DAGs**\n",
        "\n",
        "**Notebooks are for exploration and communication, source files are for repetition**\n",
        "\n",
        "**Refactor the good parts into source code**\n",
        "\n",
        "**Keep your modeling organized**\n",
        "\n",
        "**Build from the environment up**\n",
        "\n",
        "**Keep secrets and configuration out of version control**\n",
        "\n",
        "**Store your secrets and config variables in a special file**\n",
        "\n",
        "**Use a package to load these variables automatically.**\n",
        "\n",
        "**AWS CLI configuration**\n",
        "\n",
        "**Encourage adaptation from a consistent default**\n",
        "\n",
        "**Examples of template adaptation and evolution**"
      ],
      "metadata": {
        "id": "WwFVTASD_slJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the template\n",
        "\n",
        "**Set up version control**\n",
        "\n",
        "**Make as a task runner**\n",
        "\n",
        "**Create a Python virtual environment**\n",
        "\n",
        "**Add your data**\n",
        "\n",
        "**Check out a branch**\n",
        "\n",
        "**Notebook & Naming convention**\n",
        "\n",
        "Now you're ready to do some analysis! Make sure that your project-specific environment is activated (you can check with which jupyter) and run jupyter notebook notebooks to open a Jupyter notebook in the notebooks/ folder. You can start by creating a new notebook and doing some exploratory data analysis. We often name notebooks with a scheme that looks like this:\n",
        "\n",
        "    0.01-pjb-data-source-1.ipynb\n",
        "\n",
        "* 0.01 - Helps leep work in chronological order. The structure is PHASE.NOTEBOOK. NOTEBOOK is just the Nth notebook in that phase to be created. For phases of the project, we generally use a scheme like the following, but you are welcome to design your own conventions:\n",
        "  * 0 - Data exploration - often just for exploratory work\n",
        "  * 1 - Data cleaning and feature creation - often writes data to data/processed or data/interim\n",
        "  * 2 - Visualizations - often writes publication-ready viz to reports\n",
        "  * 3 - Modeling - training machine learning models\n",
        "  * 4 - Publication - Notebooks that get turned directly into reports\n",
        "* pjb - Your initials; this is helpful for knowing who created the notebook and prevents collisions from people working in the same notebook.\n",
        "* data-source-1 - A description of what the notebook covers\n",
        "Now that you have your notebook going, start your analysis!\n",
        "\n",
        "**Refactoring code into shared modules**\n",
        "\n",
        "**Make your code reviewable**\n",
        "\n",
        "**Changing the Makefile**\n",
        "\n",
        "**Installing Make on Windows**"
      ],
      "metadata": {
        "id": "2Re9CyZe9yAy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MDZBnte89w2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxTQQiSZ4a8m"
      },
      "outputs": [],
      "source": []
    }
  ]
}